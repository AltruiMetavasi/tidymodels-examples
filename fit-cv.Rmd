---
title: "Hyperparameter tuning"
author: "R. Dimas Bagas Herlambang"
date: "`r format(Sys.Date(), '%B %e, %Y')`"
output:
  html_document:
    theme: cosmo
    highlight: tango
    toc: true
    toc_float:
      collapsed: false
    df_print: paged
---

```{r setup, include=FALSE}
# clear-up the environment
rm(list = ls())

# chunk options
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  fig.asp = 0.5625,
  fig.align = "center",
  out.width = "85%",
  comment = "#>"
)

# import libs
library(plotly)
library(ranger)
library(tidyverse)
library(tidymodels)
```

## Data Preparation

### Import Dataset

```{r data-import}
# import dataset
data_clean <- read_csv("data/data-clean.csv")

# quick check
head(data_clean, 10)
```

## Data Preprocess

### Initial Split

```{r preproc-initial_split}
# set seed
set.seed(100)

# create initial split
splitted <- initial_split(data_clean, prop = 0.8, strata = "attrition")

# quick check
splitted
```

### Defining Preprocess Recipe

```{r preproc-rec}
# define preprocess recipe from train dataset
rec <- recipe(attrition ~ ., data = training(splitted)) %>% 
  step_rm(employee_count, employee_number) %>%
  step_nzv(all_predictors()) %>% 
  step_string2factor(all_nominal(), -attrition) %>%
  step_string2factor(attrition, levels = c("yes", "no")) %>%
  step_downsample(attrition, ratio = 1/1, seed = 100) %>%
  step_center(all_numeric()) %>%
  step_scale(all_numeric()) %>%
  prep(strings_as_factors = FALSE)

# quick check
head(juice(rec), 10)
```

### Cross-Validation Scheme

```{r preproc-vfold_cv}
# set seed
set.seed(100)

# create cv split
cv_split <- vfold_cv(juice(rec), v = 3, repeats = 2, strata = "attrition")

# quick check
cv_split
```

## Model Fitting

### Defining Model Specifications

```{r model-engine}
# define model specification
model_engine <- rand_forest(mode = "classification")

# define model engine
model_engine <- set_engine(
  object = model_engine,
  engine = "ranger",
  seed = 100,
  num.threads = parallel::detectCores(),
  importance = "impurity"
)

# quick check
model_engine
```

### Defining Parameter Grid

```{r model-grid}
# set-up model grid
model_grid <- grid_regular(
  range_set(mtry, range = c(2, ncol(juice(rec)) - 2)),
  range_set(trees, range = c(500, 1500)),
  range_set(min_n, range = c(1, 30)),
  levels = 3
)

# quick check
model_grid
```

### Model Fitting

```{r model-fit}
# merge model engine and grid
model_specs <- tibble(spec = merge(model_engine, model_grid)) %>%
  mutate(spec_id = str_pad(row_number(), width = 2, side = "left", pad = "0"))

# give every spec in model grid an id
model_grid <- model_grid %>%
  mutate(spec_id = str_pad(row_number(), width = 2, side = "left", pad = "0"))

# cross cv splits and model specs
crossed <- crossing(cv_split, model_specs)

# fit on every folds
crossed <- crossed %>%
  mutate(model = map2(spec, splits, ~
    fit_xy(.x, x = select(analysis(.y), -attrition), y = select(analysis(.y), attrition))
  ))

# quick check
head(crossed, 10)
```

## Cross-Validation Results

### Get Prediction on Hold-out Sample

```{r results-predict}
# get hold-out prediction in every folds
cv_result <- crossed %>%
  mutate(prediction = map2(model, splits, ~
    assessment(.y) %>%
      bind_cols(predict(.x, new_data = assessment(.y))) %>%
      bind_cols(predict(.x, new_data = assessment(.y), type = "prob")) %>%
      select(attrition, starts_with(".pred"))
  ))

# unnest the cv result
cv_result <- cv_result %>%
  select(spec_id, id, id2, prediction) %>%
  unnest(prediction)

# get metrics for every model
grid_result <- cv_result %>%
  group_by(spec_id, id, id2) %>%
  summarise(
    sensitivity = sens_vec(attrition, .pred_class),
    precision = precision_vec(attrition, .pred_class)
  ) %>%
  ungroup()

# join with model grid
grid_result <- grid_result %>% 
  left_join(model_grid)

# quick check
head(grid_result, 10)
```

### Sensitivity

```{r results-sensitivity}
# plot the result
ggplot(grid_result, aes(x = as.factor(mtry), y = sensitivity)) +
  geom_boxplot(aes(fill = as.factor(trees))) +
  coord_flip() +
  facet_wrap(~ min_n, ncol = 3, labeller = "label_both") +
  labs(x = "mtry", y = "Sensitivity", fill = "trees") +
  theme_minimal()
```

### Precision

```{r results-precision}
# plot the result
ggplot(grid_result, aes(x = as.factor(mtry), y = precision)) +
  geom_boxplot(aes(fill = as.factor(trees))) +
  coord_flip() +
  facet_wrap(~ min_n, ncol = 3) +
  labs(x = "mtry", y = "Precision", fill = "trees") +
  theme_minimal()
```
